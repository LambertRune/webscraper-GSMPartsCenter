# Quick Start Guide

## ğŸš€ Getting Started

### 1ï¸âƒ£ Install Dependencies
```bash
npm install
```

### 2ï¸âƒ£ Option A: Generate Test Data (Quick Test)
```bash
# Create sample data for testing
npm run test-data

# Start the API server
npm run api

# Test in browser or with curl:
# http://localhost:3100/health
# http://localhost:3100/api/brands
# http://localhost:3100/api/parts
```

### 2ï¸âƒ£ Option B: Scrape Real Data (Takes Time!)
```bash
# Run the scraper (will take ~30-60 minutes)
npm run scrape

# Start the API server
npm run api
```

## ğŸ“‹ Available Commands

```bash
npm run scrape      # Run the web scraper
npm run api         # Start the API server
npm run test-data   # Generate sample data for testing
```

## ğŸ” API Endpoints

### Basic Endpoints
```
GET /health                  â†’ Health check
GET /api/brands             â†’ All brands
GET /api/categories         â†’ All categories
GET /api/models             â†’ All models
GET /api/parts              â†’ All parts
```

### Search Endpoints (with filters)
```
GET /api/search/brands?name=Apple
GET /api/search/categories?brand=Samsung
GET /api/search/models?brand=Apple&modelCategory=iPhone
GET /api/search/parts?brand=Apple&model=iPhone 15&inStock=true
```

## ğŸ“ File Structure

```
webscraper-GSMPartsCenter/
â”œâ”€â”€ data/                    # JSON data files (created by scraper)
â”‚   â”œâ”€â”€ brands.json
â”‚   â”œâ”€â”€ categories.json
â”‚   â”œâ”€â”€ models.json
â”‚   â””â”€â”€ parts.json
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.js              # API server (reads from JSON)
â”‚   â”œâ”€â”€ test-data.js        # Test data generator
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ scraperService.js  # Web scraper (writes to JSON)
â”‚   â””â”€â”€ models_deprecated/  # Old MongoDB models (not used)
â”œâ”€â”€ ARCHITECTURE.md         # Technical details
â”œâ”€â”€ MIGRATION.md           # Migration summary
â””â”€â”€ README.md              # Project overview
```

## âœ… What Changed?

**Before:** Scraper â†’ MongoDB â†’ API
**After:** Scraper â†’ JSON Files â†’ API (100x faster! ğŸš€)

- âœ… Removed MongoDB dependency
- âœ… API reads from JSON files directly
- âœ… Smart diff: only updates changed parts
- âœ… All endpoints work exactly the same
- âœ… No breaking changes!

## ğŸ¯ Production Deployment

1. Run scraper to generate data: `npm run scrape`
2. Start API server: `npm run api`
3. Deploy with Dokploy (configured for auto-routing)
4. Set up cron job for daily scraping (see daily-job.sh)

## ğŸ’¡ Tips

- The `/data` folder is automatically created
- JSON files are human-readable (great for debugging!)
- Re-run scraper anytime to refresh data
- No database needed - just files!

## ğŸ†˜ Troubleshooting

**Problem:** API returns empty arrays
**Solution:** Run `npm run test-data` or `npm run scrape` first

**Problem:** Port 3100 already in use
**Solution:** Change PORT in `.env` file

**Problem:** Scraper fails
**Solution:** Check your internet connection and website availability

---

**Ready to test?** Run: `npm run test-data && npm run api`
